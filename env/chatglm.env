# https://python.langchain.com/docs/integrations/llms/chatglm

# Server address for the chatglm model
LOCALHOST_SERVER=http://127.0.0.1:1234

# Maximum number of tokens allowed in the generated response
MAX_TOKENS=80000

# Top-p (nucleus) sampling probability for generating responses (0.0 to 1.0)
TOP_P=0.9